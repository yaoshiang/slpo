============================= test session starts ==============================
platform linux -- Python 3.11.13, pytest-8.4.2, pluggy-1.6.0 -- /home/yaoshiang/miniconda3/envs/slpo/bin/python3.11
cachedir: .pytest_cache
rootdir: /home/yaoshiang/Documents/GitHub/slpo
configfile: pyproject.toml
plugins: anyio-4.11.0, hydra-core-1.3.2
collecting ... collected 1 item

test/unit/slpo/slpo_test.py::test_slpo_trains_model[1-8-128000-0.1-101] slpo.py::slpo_loss:
  input = tensor([[0.00183641994152803, 0.00167302366695237, 0.99816358005847183,
         0.99832697633304768]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=0, idx=0, loss=0.0000 0402 1559:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183642473864932, 0.00167301929284129, 0.99816357526135058,
         0.99832698070715864]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=1, idx=0, loss=0.0000 0402 1340:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183642713380037, 0.00167301710267904, 0.99816357286619961,
         0.99832698289732091]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=2, idx=0, loss=0.0000 0402 1230:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183642872829320, 0.00167301564672046, 0.99816357127170685,
         0.99832698435327949]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=3, idx=0, loss=0.0000 0402 1157:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183642992843167, 0.00167301455164135, 0.99816357007156831,
         0.99832698544835852]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=4, idx=0, loss=0.0000 0402 1103:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643089127450, 0.00167301366189013, 0.99816356910872550,
         0.99832698633810979]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=5, idx=0, loss=0.0000 0402 1058:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643169193672, 0.00167301293391218, 0.99816356830806319,
         0.99832698706608780]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=6, idx=0, loss=0.0000 0402 1022:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643238163325, 0.00167301230548704, 0.99816356761836689,
         0.99832698769451300]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=7, idx=0, loss=0.0000 0402 0990:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643298255714, 0.00167301177039252, 0.99816356701744291,
         0.99832698822960741]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=8, idx=0, loss=0.0000 0402 0963:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643351860874, 0.00167301127885236, 0.99816356648139115,
         0.99832698872114767]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=9, idx=0, loss=0.0000 0402 0939:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643400003104, 0.00167301084331060, 0.99816356599996903,
         0.99832698915668927]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=10, idx=0, loss=0.0000 0402 0917:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643443706697, 0.00167301044510107, 0.99816356556293306,
         0.99832698955489885]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=11, idx=0, loss=0.0000 0402 0897:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643482971657, 0.00167301007800178, 0.99816356517028348,
         0.99832698992199809]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=12, idx=0, loss=0.0000 0402 0879:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643520188011, 0.00167300974823463, 0.99816356479811985,
         0.99832699025176530]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=13, idx=0, loss=0.0000 0402 0862:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643553990032, 0.00167300944335566, 0.99816356446009979,
         0.99832699055664431]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=14, idx=0, loss=0.0000 0402 0847:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643585914171, 0.00167300914469878, 0.99816356414085827,
         0.99832699085530119]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=15, idx=0, loss=0.0000 0402 0832:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643615277550, 0.00167300887715201, 0.99816356384722438,
         0.99832699112284795]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=16, idx=0, loss=0.0000 0402 0818:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643643445913, 0.00167300861582729, 0.99816356356554092,
         0.99832699138417269]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=17, idx=0, loss=0.0000 0402 0805:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643669907108, 0.00167300837939070, 0.99816356330092904,
         0.99832699162060934]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=18, idx=0, loss=0.0000 0402 0793:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643695344001, 0.00167300814917615, 0.99816356304656007,
         0.99832699185082396]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=19, idx=0, loss=0.0000 0402 0782:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643719073721, 0.00167300794384965, 0.99816356280926277,
         0.99832699205615039]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=20, idx=0, loss=0.0000 0402 0771:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643741779139, 0.00167300774474519, 0.99816356258220862,
         0.99832699225525467]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=21, idx=0, loss=0.0000 0402 0761:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643763630975, 0.00167300754564078, 0.99816356236369019,
         0.99832699245435919]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=22, idx=0, loss=0.0000 0402 0751:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643784629229, 0.00167300734653643, 0.99816356215370772,
         0.99832699265346359]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=23, idx=0, loss=0.0000 0402 0741:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643805286048, 0.00167300715365408, 0.99816356194713951,
         0.99832699284634596]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=24, idx=0, loss=0.0000 0402 0732:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643825089284, 0.00167300696077178, 0.99816356174910714,
         0.99832699303922812]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=25, idx=0, loss=0.0000 0402 0723:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643842673194, 0.00167300679277754, 0.99816356157326802,
         0.99832699320722240]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=26, idx=0, loss=0.0000 0402 0714:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643860086383, 0.00167300663100528, 0.99816356139913620,
         0.99832699336899466]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=27, idx=0, loss=0.0000 0402 0706:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643877328857, 0.00167300646923304, 0.99816356122671146,
         0.99832699353076704]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=28, idx=0, loss=0.0000 0402 0698:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643893717748, 0.00167300630746085, 0.99816356106282245,
         0.99832699369253919]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=29, idx=0, loss=0.0000 0402 0691:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643909935919, 0.00167300617057667, 0.99816356090064084,
         0.99832699382942325]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=30, idx=0, loss=0.0000 0402 0683:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643925471224, 0.00167300603369253, 0.99816356074528778,
         0.99832699396630753]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=31, idx=0, loss=0.0000 0402 0676:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643940835808, 0.00167300590303036, 0.99816356059164191,
         0.99832699409696979]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=32, idx=0, loss=0.0000 0402 0670:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643956029677, 0.00167300577236821, 0.99816356043970322,
         0.99832699422763171]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=33, idx=0, loss=0.0000 0402 0663:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643970540678, 0.00167300564170609, 0.99816356029459330,
         0.99832699435829386]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=34, idx=0, loss=0.0000 0402 0656:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643984880964, 0.00167300551104399, 0.99816356015119034,
         0.99832699448895601]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=35, idx=0, loss=0.0000 0402 0650:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183643997684788, 0.00167300540526989, 0.99816356002315210,
         0.99832699459473007]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=36, idx=0, loss=0.0000 0402 0644:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644009805746, 0.00167300529949583, 0.99816355990194250,
         0.99832699470050412]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=37, idx=0, loss=0.0000 0402 0639:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644021755987, 0.00167300519372177, 0.99816355978244009,
         0.99832699480627829]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=38, idx=0, loss=0.0000 0402 0633:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644033706224, 0.00167300509416968, 0.99816355966293768,
         0.99832699490583043]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=39, idx=0, loss=0.0000 0402 0628:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644045656461, 0.00167300499461759, 0.99816355954343539,
         0.99832699500538236]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=40, idx=0, loss=0.0000 0402 0623:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644057435982, 0.00167300489506551, 0.99816355942564017,
         0.99832699510493450]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=41, idx=0, loss=0.0000 0402 0618:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644068532636, 0.00167300479551347, 0.99816355931467360,
         0.99832699520448642]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=42, idx=0, loss=0.0000 0402 0613:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644079458573, 0.00167300469596144, 0.99816355920541433,
         0.99832699530403857]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=43, idx=0, loss=0.0000 0402 0608:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644090384511, 0.00167300459640941, 0.99816355909615495,
         0.99832699540359049]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=44, idx=0, loss=0.0000 0402 0603:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644101310449, 0.00167300449685739, 0.99816355898689546,
         0.99832699550314274]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=45, idx=0, loss=0.0000 0402 0598:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644112065671, 0.00167300439730539, 0.99816355887934327,
         0.99832699560269467]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=46, idx=0, loss=0.0000 0402 0593:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644122138025, 0.00167300429775341, 0.99816355877861973,
         0.99832699570224659]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=47, idx=0, loss=0.0000 0402 0588:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644132210380, 0.00167300419820144, 0.99816355867789630,
         0.99832699580179851]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=48, idx=0, loss=0.0000 0402 0583:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644142112018, 0.00167300409864948, 0.99816355857887984,
         0.99832699590135043]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=49, idx=0, loss=0.0000 0402 0579:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644152013656, 0.00167300399909753, 0.99816355847986349,
         0.99832699600090236]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=50, idx=0, loss=0.0000 0402 0574:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644161915290, 0.00167300390576753, 0.99816355838084703,
         0.99832699609423237]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=51, idx=0, loss=0.0000 0402 0569:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644171646208, 0.00167300381243755, 0.99816355828353798,
         0.99832699618756238]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=52, idx=0, loss=0.0000 0402 0565:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644181377125, 0.00167300371910757, 0.99816355818622871,
         0.99832699628089250]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=53, idx=0, loss=0.0000 0402 0560:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644190425175, 0.00167300362577762, 0.99816355809574819,
         0.99832699637422251]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=54, idx=0, loss=0.0000 0402 0556:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644199473225, 0.00167300353244768, 0.99816355800526779,
         0.99832699646755230]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=55, idx=0, loss=0.0000 0402 0551:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644208521275, 0.00167300343911774, 0.99816355791478728,
         0.99832699656088231]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=56, idx=0, loss=0.0000 0402 0547:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644217398609, 0.00167300334578781, 0.99816355782601396,
         0.99832699665421210]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=57, idx=0, loss=0.0000 0402 0543:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644226275943, 0.00167300325245789, 0.99816355773724064,
         0.99832699674754211]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=58, idx=0, loss=0.0000 0402 0538:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644233787530, 0.00167300318401593, 0.99816355766212472,
         0.99832699681598402]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=59, idx=0, loss=0.0000 0402 0535:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644241299118, 0.00167300311557396, 0.99816355758700881,
         0.99832699688442594]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=60, idx=0, loss=0.0000 0402 0531:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644248810706, 0.00167300304713200, 0.99816355751189290,
         0.99832699695286797]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=61, idx=0, loss=0.0000 0402 0528:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644256151577, 0.00167300297869005, 0.99816355743848417,
         0.99832699702130989]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=62, idx=0, loss=0.0000 0402 0524:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644263492448, 0.00167300291024810, 0.99816355736507545,
         0.99832699708975181]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=63, idx=0, loss=0.0000 0402 0521:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644270150451, 0.00167300284180618, 0.99816355729849549,
         0.99832699715819373]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=64, idx=0, loss=0.0000 0402 0518:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644276808453, 0.00167300277336426, 0.99816355723191541,
         0.99832699722663565]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=65, idx=0, loss=0.0000 0402 0515:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644283466457, 0.00167300270492235, 0.99816355716533545,
         0.99832699729507757]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=66, idx=0, loss=0.0000 0402 0511:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644289953743, 0.00167300263648044, 0.99816355710046245,
         0.99832699736351949]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=67, idx=0, loss=0.0000 0402 0508:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644296441029, 0.00167300256803854, 0.99816355703558968,
         0.99832699743196140]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=68, idx=0, loss=0.0000 0402 0505:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644302928315, 0.00167300249959664, 0.99816355697071690,
         0.99832699750040332]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=69, idx=0, loss=0.0000 0402 0502:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644309415602, 0.00167300243115474, 0.99816355690584391,
         0.99832699756884524]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=70, idx=0, loss=0.0000 0402 0499:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644315902884, 0.00167300236893479, 0.99816355684097124,
         0.99832699763106536]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=71, idx=0, loss=0.0000 0402 0496:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644322390166, 0.00167300230671484, 0.99816355677609847,
         0.99832699769328515]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=72, idx=0, loss=0.0000 0402 0493:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644328877448, 0.00167300224449490, 0.99816355671122547,
         0.99832699775550515]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=73, idx=0, loss=0.0000 0402 0490:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644335194013, 0.00167300218227496, 0.99816355664805989,
         0.99832699781772516]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=74, idx=0, loss=0.0000 0402 0487:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644341510578, 0.00167300212005503, 0.99816355658489420,
         0.99832699787994494]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=75, idx=0, loss=0.0000 0402 0484:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644347827144, 0.00167300205783510, 0.99816355652172861,
         0.99832699794216495]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=76, idx=0, loss=0.0000 0402 0481:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644354143709, 0.00167300199561517, 0.99816355645856281,
         0.99832699800438474]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=77, idx=0, loss=0.0000 0402 0478:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644359777406, 0.00167300193339526, 0.99816355640222598,
         0.99832699806660474]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=78, idx=0, loss=0.0000 0402 0475:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644365411102, 0.00167300187117537, 0.99816355634588894,
         0.99832699812882453]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=79, idx=0, loss=0.0000 0402 0472:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644371044799, 0.00167300180895547, 0.99816355628955189,
         0.99832699819104453]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=80, idx=0, loss=0.0000 0402 0469:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644376678496, 0.00167300174673557, 0.99816355623321507,
         0.99832699825326432]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=81, idx=0, loss=0.0000 0402 0466:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644382312193, 0.00167300168451568, 0.99816355617687802,
         0.99832699831548444]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=82, idx=0, loss=0.0000 0402 0463:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644387775173, 0.00167300162229579, 0.99816355612224816,
         0.99832699837770422]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=83, idx=0, loss=0.0000 0402 0461:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644393238154, 0.00167300156007591, 0.99816355606761842,
         0.99832699843992401]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=84, idx=0, loss=0.0000 0402 0458:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644398701134, 0.00167300149785603, 0.99816355601298878,
         0.99832699850214401]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=85, idx=0, loss=0.0000 0402 0455:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644404164114, 0.00167300143563616, 0.99816355595835893,
         0.99832699856436380]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=86, idx=0, loss=0.0000 0402 0452:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644409627095, 0.00167300137341628, 0.99816355590372907,
         0.99832699862658381]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=87, idx=0, loss=0.0000 0402 0449:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644415090072, 0.00167300133608433, 0.99816355584909933,
         0.99832699866391572]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=88, idx=0, loss=0.0000 0402 0447:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644420553048, 0.00167300129875237, 0.99816355579446947,
         0.99832699870124764]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=89, idx=0, loss=0.0000 0402 0445:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644426016025, 0.00167300126142041, 0.99816355573983984,
         0.99832699873857955]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=90, idx=0, loss=0.0000 0402 0443:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644431479002, 0.00167300122408846, 0.99816355568520998,
         0.99832699877591147]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=91, idx=0, loss=0.0000 0402 0441:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644436941979, 0.00167300118675650, 0.99816355563058023,
         0.99832699881324338]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=92, idx=0, loss=0.0000 0402 0438:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644442404956, 0.00167300114942455, 0.99816355557595038,
         0.99832699885057530]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=93, idx=0, loss=0.0000 0402 0436:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644447697216, 0.00167300111209260, 0.99816355552302782,
         0.99832699888790744]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=94, idx=0, loss=0.0000 0402 0434:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644452989476, 0.00167300107476066, 0.99816355547010516,
         0.99832699892523946]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=95, idx=0, loss=0.0000 0402 0432:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644458281736, 0.00167300103742872, 0.99816355541718260,
         0.99832699896257138]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=96, idx=0, loss=0.0000 0402 0430:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644463573997, 0.00167300100009677, 0.99816355536426005,
         0.99832699899990329]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=97, idx=0, loss=0.0000 0402 0428:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644468866258, 0.00167300096276483, 0.99816355531133738,
         0.99832699903723521]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=98, idx=0, loss=0.0000 0402 0425:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

slpo.py::slpo_loss:
  input = tensor([[0.00183644474158518, 0.00167300092543289, 0.99816355525841483,
         0.99832699907456712]], dtype=torch.float64, grad_fn=<ExpBackward0>)
  target = tensor([[0.00200372230822327, 0.00150572130025713, 0.99799627769177679,
         0.99849427869974283]], dtype=torch.float64)

epoch=99, idx=0, loss=0.0000 0402 0423:
    prob_w = 0.0000 0000 0000
    prob_l = 0.0000 0000 0000

INITIAL:loss=0.0000 0402 1559
   ref_prob_w = 0.0000 0000 0000
   ref_prob_l = 0.0000 0000 0000
target_logp_w = 0.0000 0000 0000
target_logp_l = 0.0000 0000 0000
       prob_w = 0.0000 0000 0000
       prob_l = 0.0000 0000 0000

FINAL: loss=0.0000 0402 0423
   ref_prob_w = 0.0000 0000 0000
   ref_prob_l = 0.0000 0000 0000
target_logp_w = 0.0000 0000 0000
target_logp_l = 0.0000 0000 0000
       prob_w = 0.0000 0000 0000
       prob_l = 0.0000 0000 0000

FAILED

=================================== FAILURES ===================================
__________________ test_slpo_trains_model[1-8-128000-0.1-101] __________________

seed = 101, alpha = 0.1, B = 1, S = 8, V = 128000

    @pytest.mark.parametrize("seed", [101, 102, 103])
    @pytest.mark.parametrize("alpha", [0.0, 0.1, 0.5, 0.9, 1.0])
    @pytest.mark.parametrize("B,S,V", [(1, 8, 128_000)])  # (1, 2048, 128_000)))
    def test_slpo_trains_model(seed, alpha, B, S, V):
      # Arrange model
      torch.manual_seed(seed)
      ref_model = fixtures.Memo(B, S, V, 2)
      model = copy.deepcopy(ref_model)
    
      # Arrange data
      # DPO dataset concepts:
      # We have a batch with chosen and rejected sequences.
      # In this synthetic test, we generate them randomly.
      # We also simulate the prompt masking by setting the first half of the labels to -100.
      prompt_len = S // 2
      response_len = S - prompt_len
    
      prompt_tokens = torch.randint(
        low=0, high=V, size=(B, prompt_len), dtype=torch.long
      )
      chosen_response = torch.randint(
        low=0, high=V, size=(B, response_len), dtype=torch.long
      )
      rejected_response = torch.randint(
        low=0, high=V, size=(B, response_len), dtype=torch.long
      )
    
      # Construct labels
      # For labels, prompt part is -100
      prompt_labels = torch.full((B, prompt_len), -100, dtype=torch.long)
      chosen_labels = torch.cat([prompt_labels, chosen_response], dim=1)
      rejected_labels = torch.cat([prompt_labels, rejected_response], dim=1)
    
      # Construct input_ids (for completeness, though Memo ignores them)
      # Input ids should have the actual prompt tokens
      chosen_input_ids = torch.cat([prompt_tokens, chosen_response], dim=1)
      rejected_input_ids = torch.cat([prompt_tokens, rejected_response], dim=1)
    
      # Construct a batch that mimics a DPO PreferenceDataset batch
      batch = {
        "chosen_labels": chosen_labels,
        "rejected_labels": rejected_labels,
        # Memo model ignores input_ids, but we provide them for completeness of the interface
        "chosen_input_ids": chosen_input_ids,
        "rejected_input_ids": rejected_input_ids,
        "prompt_input_ids": prompt_tokens,
      }
    
      # DataLoader yields batches
      loader = [batch]
    
      # Setup training loop
      optim = torch.optim.SGD(
        model.parameters(), lr=0.0
      )  # LR will be set per epoch
    
      for epoch in range(100):
        optim.param_groups[0]["lr"] = 1.0 / (epoch + 1.0)
        for idx, batch in enumerate(loader):
          # Unpack batch
          chosen_labels = batch["chosen_labels"]
          rejected_labels = batch["rejected_labels"]
          chosen_input_ids = batch["chosen_input_ids"]
          rejected_input_ids = batch["rejected_input_ids"]
    
          optim.zero_grad()
    
          # Forward pass for chosen and rejected
          def concat_func(batch):
            return {
              "concatenated_input_ids": torch.cat(
                [batch["chosen_input_ids"], batch["rejected_input_ids"]], dim=0
              ),
              "concatenated_labels": torch.cat(
                [batch["chosen_labels"], batch["rejected_labels"]], dim=0
              ),
              "concatenated_attention_mask": torch.ones_like(
                torch.cat(
                  [batch["chosen_input_ids"], batch["rejected_input_ids"]], dim=0
                )
              ),
            }
    
          logp_w, logp_l, logp_wbar, logp_lbar = slpo.concatenated_forward(
            model, batch, concat_func
          )
    
          with torch.inference_mode():
            ref_logp_w, ref_logp_l, _, _ = slpo.concatenated_forward(
              ref_model, batch, concat_func
            )
    
          loss, _, _ = slpo.slpo_loss(
            logp_w,
            logp_l,
            logp_wbar,
            logp_lbar,
            ref_logp_w,
            ref_logp_l,
            alpha,
            t=float(S),
          )
    
          loss.backward()
          optim.step()
    
          print(
            f"{epoch=}, {idx=}, loss={format(loss)}:\n"
            f"    prob_w = {format(logp_w.exp())}\n"
            f"    prob_l = {format(logp_l.exp())}\n"
          )
    
          if epoch == 0 and idx == 0:
            initial_loss = loss.detach()
            initial_logp_w = logp_w.detach()
            initial_logp_l = logp_l.detach()
            initial_logp_wbar = logp_wbar.detach()
            initial_logp_lbar = logp_lbar.detach()
    
          if torch.isnan(loss):
            raise ValueError("Loss is NaN")
    
      final_loss = loss.detach()
      final_logp_w = logp_w.detach()
      final_logp_l = logp_l.detach()
      final_logp_wbar = logp_wbar.detach()
      final_logp_lbar = logp_lbar.detach()
    
      # Verify that the model converged to the target distribution
      # w_w et al were calculcated on temperature adjusted logprobs. But that is
      # an internal implementation detail. So recreate those weights without
      # temperature.
      target_logp_w, target_logp_l, target_logp_wbar, target_logp_lbar = (
        slpo.calc_targets(alpha, ref_logp_w, ref_logp_l)
      )
    
      print(
        f"INITIAL:loss={format(initial_loss)}\n"
        f"   ref_prob_w = {format(ref_logp_w.exp())}\n"
        f"   ref_prob_l = {format(ref_logp_l.exp())}\n"
        f"target_logp_w = {format(target_logp_w.exp())}\n"
        f"target_logp_l = {format(target_logp_l.exp())}\n"
        f"       prob_w = {format(final_logp_w.exp())}\n"
        f"       prob_l = {format(final_logp_l.exp())}\n"
      )
      print(
        f"FINAL: loss={format(final_loss)}\n"
        f"   ref_prob_w = {format(ref_logp_w.exp())}\n"
        f"   ref_prob_l = {format(ref_logp_l.exp())}\n"
        f"target_logp_w = {format(target_logp_w.exp())}\n"
        f"target_logp_l = {format(target_logp_l.exp())}\n"
        f"       prob_w = {format(final_logp_w.exp())}\n"
        f"       prob_l = {format(final_logp_l.exp())}\n"
      )
    
      torch.testing.assert_close(
        slpo._logsumexp(logp_w, logp_wbar), torch.zeros_like(logp_w)
      )
      torch.testing.assert_close(
        slpo._logsumexp(logp_l, logp_lbar), torch.zeros_like(logp_l)
      )
    
      # 90% of the way there is good enough.
      atol = 0.1 * (initial_logp_w - target_logp_w).abs().item()
>     torch.testing.assert_close(
        final_logp_w,
        target_logp_w,
        atol=atol,
        rtol=0.0,
        msg=f"winner logp did not converge to target\n{final_logp_w=}\n{target_logp_w=}",
      )
E     AssertionError: winner logp did not converge to target
E     final_logp_w=tensor([-50.38468519252262467], dtype=torch.float64)
E     target_logp_w=tensor([-50.33849360600697764], dtype=torch.float64)

test/unit/slpo/slpo_test.py:567: AssertionError
=========================== short test summary info ============================
FAILED test/unit/slpo/slpo_test.py::test_slpo_trains_model[1-8-128000-0.1-101]
============================== 1 failed in 5.03s ===============================
